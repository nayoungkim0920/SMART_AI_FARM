yolov5 in PC

1. CUDA cuDNN 설치 합니다.
CUDA 버전확인: nvidia-smi
CUDA : 12.0
CUDA capability : 8.6
https://developer.nvidia.com/cuda-toolkit-archive
https://developer.nvidia.com/rdp/cudnn-archive
CUDA Toolkit 12.0.0 (December 2022), Versioned Online Documentation, windows11
C:\Users\nayou\AppData\Local\Temp\cuda
nvidia 가입 후 로그인
Download cuDNN v8.9.7 (December 5th, 2023), for CUDA 12.x
Local Installers for Windows and Linux, Ubuntu(x86_64, armsbsa)
Local Installer for Windows (Zip)
-SDK설치경로에 다운로드받은 폴더를 추가합니다.(include, lib, bin)
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.0

2. git을 다운로드받습니다.
https://git-scm.com/
C:\Program Files\Git

3. git환경변수를 추가해주고 재부팅합니다.
C:\Program Files\Git\bin
명령프롬프트에서 KMP_DUPLICATE_LIB_OK=TRUE 환경변수를 등록해줍니다.

1. anaconda를 설치합니다. vscode를 설치합니다.
https://code.visualstudio.com/download
C:\Users\nayou\AppData\Local\Programs\Microsoft VS Code

2. github에서 yolov5를 다운로드합니다.
https://github.com/ultralytics/yolov5
code > download zip
c:\yolov5

3. anaconda prompt를 관리자 권한으로 실행하고 아래대로 실행합니다.
conda create --name py39 python=3.9
conda activate py39
conda update conda
cd C:\yolov5
pip install -r requirements.txt

4. Run yolov5 in Local PC with CLI
python detect.py --weights yolov5n.pt --img 640 --conf 0.25 --source data/images
runs/detect/exp

5. Train(opendataset COCO128, 학습 오픈데이터셋으로 yolov5학습 튜토리얼)
python train.py --img 640 --batch 1 --epochs 1 --data coco128.yaml --weights yolov5n.pt
Results saved to runs\train\exp2

6. 직접만든 데이터셋으로 학습시키기
python c:/yolov5/train.py --img 640 --batch 16 --epochs 250 --data c:/data.yaml --weights c:/yolov5/models/yolov5m.pt --device 0
(base) c:\yolov5>python c:/yolov5/train.py --img 640 --batch 1 --epochs 100 --data c:/cup_test/data.yaml --weights yolov5n.pt --device 0
 Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
       0/99      0.51G    0.05364     0.0261    0.01911          2        640: 100%|██████████| 643/643 [00:35<00:
                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 35/35 [
                   all         69         78       0.79       0.16      0.148     0.0492

Model summary: 157 layers, 1763224 parameters, 0 gradients, 4.1 GFLOPs
                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 35/35 [
                   all         69         78      0.921      0.986      0.992      0.836
                bottle         69          3      0.827          1      0.995      0.841
                   cup         69         60          1      0.972      0.995      0.848
               tumbler         69         15      0.937      0.986      0.987      0.819
Results saved to runs\train\exp12

7. 만들어진 best.pt로 검출하기
python c:/yolov5/detect.py --weights C:\yolov5\runs\train\exp25\weights\best.pt --img 640 --conf 0.70 --source C:\images --device 0


8. 최적화
python c:/yolov5/train.py --img 640 --batch 16 --epochs 250 --data c:/data.yaml --weights c:/yolov5/models/yolov5m.pt --device 0 --name experiment_name --optimizer Adam --project project_directory
Adam은 Adaptive Moment Estimation(적응적 모멘트 추정)의 약자로, SGD의 단점을 보완하기 위해 제안된 옵티마이저입니다.
각 파라미터마다 학습률을 조정하고, 지수 가중 이동 평균을 사용하여 각 매개변수의 스케일을 조정합니다.
이러한 특징으로 인해 Adam은 일반적으로 SGD보다 더 빠르게 수렴하고 더 나은 성능을 보입니다.
-bach를 바꿔 학습시킵니다
python c:/yolov5/train.py --img 640 --batch 8 --epochs 100 --data c:/data.yaml --weights c:/yolov5/models/yolov5m.pt --device 0 --name exp --optimizer Adam --project c:\yolov5result
옵션설명
python : 스크립트를 실행하는 데 사용할 Python 인터프리터 지정
c:/yolov5/train.py : YOLOv5를 훈련하는 데 사용되는 Python 스크립트 train.py의 경로
--img 640 : 이미지의 크기를 640X640 픽셀로 설정, 이미지의 크기가 클 수록 성능이 향상되지만 훈련시간이 늘어날 수 있음
--batch 8 : 배치의 크기설정, 한 번에 모델에 공급되는 이미지의 수, 한번에 8개의 이미지가 모델에 공급, 
            더 큰 배치를 사용하면 GPU가 더 많은 데이터를 처리할 수 있어 훈련 속도가 향상되지만, 그만큼  더 많은 메모리가 필요함
--epochs 100 : YOLOv5훈련 중에 전체 데이터셋을 몇 번 반복해서 사용할지를 결정함, 모델이 데이터셋을 한번 통과할 때마다 한 번의 에포크가 진행됨
               에포크 수는 훈련과정에서 데이터셋을 모델에 노출시키는 횟수 결정, 일반적으로 더 많은 에포크를 사용할수록 모델의 성능이 향상,
               과적(overfitting)을 방지하기 위해 적절한 수준에서 훈련을 중단해야함
--data c:/data.yaml : 데이터 구성을 정의 하는 YAML파일의 경로, 데이터 구성은 클래스 이름, 학습 및 검증 이미지의 경로 등 포함
--weights c:/yolov5/models/yolov5m.pt : 사전 훈련된 모델 가중치 파일의 경로, 훈련을 시작하기 전에 초기 가중치로 사용
--device 0 : 사용할 디바이스 설정, 0은 첫번째 GPU를 가리킴, GPU가 없는 경우 --device cpu로 설정
--name exp : 훈련 실험의 이름 설정, 훈련 중에 생성된 결과 디렉토리에 사용
--optimizer Adam : 옵티마이저 설정
--project c:/yolov5result : 결과를 저장할 프로젝트 디렉토리의 경로, 훈련 중에 생성된 모든 파일 및 로그가 저장됨

data.yaml
train: c:/cup_test/train/images #휸련 데이터셋 이미지의 디렉토리 경로 지정
val: c:/cup_test/valid/images #검증 데이터셋 이미지의 디렉토리 경로 지정
test: c:/cup_test/test/images #테스트 데이터셋 이미지의 디렉토리 경로 지정

nc: 3 //데이터셋에 있는 클래스의 총개수 
names: ['bottle', 'cup', 'tumbler'] #클래스 이름의 리스트를 제공, nc의 숫자와 동일한 길이를 가지고 각 클래스이름은 따옴표속에 넣음

#데이터 증강(argumentation), YOLOv5에서 훈련할 때 데이터를 다양하게 변형하여 모델의 일반화 성능을 향상
mosaic: True  # Mosaic 데이터 증강 활성화, 네 개의 이미지를 하나의 이미지로 결합하여 훈련 데이터셋을 확장하는 방법,
              # 이를 통해 모델은 여러 객체와 배경을 동시에 볼 수 있으며, 모델의 일반화 성능을 향상시킬 수 있음
mixup: 0.5  # Mixup 데이터 증강 비율 (0 ~ 1), 데이터 증강을 적용하는 비율
            # 두 개의 이미지를 섞어서 새로운 이미지를 생성하는 방법, 
            # 두 이미지의 픽셀값을 선형으로 조합하여새로운 이미지를 생성
            # 모델은 다양한 이미지를 처리하고 과적합을 줄일 수있음.
            # 0qnxj 1tkd

roboflow:
  workspace: nayoungkim-xrg93
  project: cup-krqrq
  version: 20
  license: CC BY 4.0
  url: https://universe.roboflow.com/nayoungkim-xrg93/cup-krqrq/dataset/20
