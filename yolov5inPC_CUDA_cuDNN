yolov5 in PC
사양:  NVIDIA GeForce RTX 4060 Laptop GPU 16G RAM

1. CUDA cuDNN 설치 합니다.
Compute Unified Device Architecture
CUDA Deep Neural Network library

CUDA 버전확인: nvidia-smi
CUDA : 12.0
CUDA capability : 8.6
https://developer.nvidia.com/cuda-toolkit-archive
https://developer.nvidia.com/rdp/cudnn-archive
CUDA Toolkit 12.0.0 (December 2022), Versioned Online Documentation, windows11
C:\Users\nayou\AppData\Local\Temp\cuda
nvidia 가입 후 로그인
Download cuDNN v8.9.7 (December 5th, 2023), for CUDA 12.x
Local Installers for Windows and Linux, Ubuntu(x86_64, armsbsa)
Local Installer for Windows (Zip)
-SDK설치경로에 다운로드받은 폴더를 추가합니다.(include, lib, bin)
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.0

2. git을 다운로드받습니다.
https://git-scm.com/
C:\Program Files\Git

3. git환경변수를 추가해주고 재부팅합니다.
C:\Program Files\Git\bin
명령프롬프트에서 KMP_DUPLICATE_LIB_OK=TRUE 환경변수를 등록해줍니다.

1. anaconda를 설치합니다. vscode를 설치합니다.
https://code.visualstudio.com/download
C:\Users\nayou\AppData\Local\Programs\Microsoft VS Code

2. github에서 yolov5를 다운로드합니다.
https://github.com/ultralytics/yolov5
code > download zip
c:\yolov5

3. anaconda prompt를 관리자 권한으로 실행하고 아래대로 실행합니다.
conda create --name py39 python=3.9
conda activate py39
conda update conda
cd C:\yolov5
pip install -r requirements.txt

4. Run yolov5 in Local PC with CLI
python detect.py --weights yolov5n.pt --img 640 --conf 0.25 --source data/images
runs/detect/exp

python c:/yolov5/detect.py --weights C:\yolov5result\exp20\weights\best.pt --img 640 --conf 0.50 --source C:\images --device 0

5. Train(opendataset COCO128, 학습 오픈데이터셋으로 yolov5학습 튜토리얼)
python train.py --img 640 --batch 1 --epochs 1 --data coco128.yaml --weights yolov5n.pt
Results saved to runs\train\exp2

6. 직접만든 데이터셋으로 학습시키기
python c:/yolov5/train.py --img 640 --batch 16 --epochs 250 --data c:/data.yaml --weights c:/yolov5/models/yolov5m.pt --device 0
(base) c:\yolov5>python c:/yolov5/train.py --img 640 --batch 1 --epochs 100 --data c:/cup_test/data.yaml --weights yolov5n.pt --device 0
 Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
       0/99      0.51G    0.05364     0.0261    0.01911          2        640: 100%|██████████| 643/643 [00:35<00:
                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 35/35 [
                   all         69         78       0.79       0.16      0.148     0.0492

Model summary: 157 layers, 1763224 parameters, 0 gradients, 4.1 GFLOPs
                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 35/35 [
                   all         69         78      0.921      0.986      0.992      0.836
                bottle         69          3      0.827          1      0.995      0.841
                   cup         69         60          1      0.972      0.995      0.848
               tumbler         69         15      0.937      0.986      0.987      0.819
Results saved to runs\train\exp12

7. 만들어진 best.pt로 검출하기
python c:/yolov5/detect.py --weights C:\yolov5\runs\train\exp25\weights\best.pt --img 640 --conf 0.70 --source C:\images --device 0


8. 최적화
python c:/yolov5/train.py --img 640 --batch 16 --epochs 250 --data c:/data.yaml --weights c:/yolov5/models/yolov5m.pt --device 0 --name experiment_name --optimizer Adam --project project_directory
Adam은 Adaptive Moment Estimation(적응적 모멘트 추정)의 약자로, SGD의 단점을 보완하기 위해 제안된 옵티마이저입니다.
각 파라미터마다 학습률을 조정하고, 지수 가중 이동 평균을 사용하여 각 매개변수의 스케일을 조정합니다.
이러한 특징으로 인해 Adam은 일반적으로 SGD보다 더 빠르게 수렴하고 더 나은 성능을 보입니다.
-bach를 바꿔 학습시킵니다
python c:/yolov5/train.py --img 640 --batch 8 --epochs 100 --data c:/data.yaml --weights c:/yolov5/models/yolov5m.pt --device 0 --name exp --optimizer Adam --project c:\yolov5result
python c:/yolov5/train.py --img 640 --batch 16 --epochs 50 --data c:/data.yaml --weights c:/yolov5/models/yolov5m.pt --device 0 --name exp --optimizer SGD --project c:/yolov5result

옵션설명
python : 스크립트를 실행하는 데 사용할 Python 인터프리터 지정
c:/yolov5/train.py : YOLOv5를 훈련하는 데 사용되는 Python 스크립트 train.py의 경로
--img 640 : 이미지의 크기를 640X640 픽셀로 설정, 이미지의 크기가 클 수록 성능이 향상되지만 훈련시간이 늘어날 수 있음
--batch 8 : 배치의 크기설정, 한 번에 모델에 공급되는 이미지의 수, 한번에 8개의 이미지가 모델에 공급, 
            더 큰 배치를 사용하면 GPU가 더 많은 데이터를 처리할 수 있어 훈련 속도가 향상되지만, 그만큼  더 많은 메모리가 필요함
--epochs 100 : YOLOv5훈련 중에 전체 데이터셋을 몇 번 반복해서 사용할지를 결정함, 모델이 데이터셋을 한번 통과할 때마다 한 번의 에포크가 진행됨
               에포크 수는 훈련과정에서 데이터셋을 모델에 노출시키는 횟수 결정, 일반적으로 더 많은 에포크를 사용할수록 모델의 성능이 향상,
               과적(overfitting)을 방지하기 위해 적절한 수준에서 훈련을 중단해야함
--data c:/data.yaml : 데이터 구성을 정의 하는 YAML파일의 경로, 데이터 구성은 클래스 이름, 학습 및 검증 이미지의 경로 등 포함
--weights c:/yolov5/models/yolov5m.pt : 사전 훈련된 모델 가중치 파일의 경로, 훈련을 시작하기 전에 초기 가중치로 사용
--device 0 : 사용할 디바이스 설정, 0은 첫번째 GPU를 가리킴, GPU가 없는 경우 --device cpu로 설정
--name exp : 훈련 실험의 이름 설정, 훈련 중에 생성된 결과 디렉토리에 사용
--optimizer Adam : 옵티마이저 설정
--optimizer SDG : Stochastic Gradient Descent는 딥러닝에서 가장 기본적인 최적화 알고리즘
--project c:/yolov5result : 결과를 저장할 프로젝트 디렉토리의 경로, 훈련 중에 생성된 모든 파일 및 로그가 저장됨

data.yaml
train: c:/cup_test/train/images #휸련 데이터셋 이미지의 디렉토리 경로 지정
val: c:/cup_test/valid/images #검증 데이터셋 이미지의 디렉토리 경로 지정
test: c:/cup_test/test/images #테스트 데이터셋 이미지의 디렉토리 경로 지정

nc: 3 //데이터셋에 있는 클래스의 총개수 
names: ['bottle', 'cup', 'tumbler'] #클래스 이름의 리스트를 제공, nc의 숫자와 동일한 길이를 가지고 각 클래스이름은 따옴표속에 넣음

#데이터 증강(argumentation), YOLOv5에서 훈련할 때 데이터를 다양하게 변형하여 모델의 일반화 성능을 향상
mosaic: True  # Mosaic 데이터 증강 활성화, 네 개의 이미지를 하나의 이미지로 결합하여 훈련 데이터셋을 확장하는 방법,
              # 이를 통해 모델은 여러 객체와 배경을 동시에 볼 수 있으며, 모델의 일반화 성능을 향상시킬 수 있음
mixup: 0.5  # Mixup 데이터 증강 비율 (0 ~ 1), 데이터 증강을 적용하는 비율
            # 두 개의 이미지를 섞어서 새로운 이미지를 생성하는 방법, 
            # 두 이미지의 픽셀값을 선형으로 조합하여새로운 이미지를 생성
            # 모델은 다양한 이미지를 처리하고 과적합을 줄일 수있음.
            # 0에 가까울 수록 Mixup을 적게 적용하고, 1에 가까울 수록 많이 적용함

roboflow:
  workspace: nayoungkim-xrg93
  project: cup-krqrq
  version: 20
  license: CC BY 4.0
  url: https://universe.roboflow.com/nayoungkim-xrg93/cup-krqrq/dataset/20

개채 감지 모델의 훈련 모니터링(Yolov5, You Only Look Once)
      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
       0/99      3.19G    0.05293    0.02123    0.01472          9        640: 100%|██████████| 83/83 [00:14<00:00,  5.
                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 6/6 [00:00<0
                   all         96         96          0          0          0          0

Epoch : 훈련 진행 상황
GPU_mem : 훈련 중 GPU메모리 사용량

!!세가지 손실을 최소화하고 낮은값으로 유지하는데 중점을 둠!!
box_loss : 박스손실, 바운딩 박스 위치 지정과 관련된 손실
obj_loss : 객체손실, 주어진 바운딩 박스에 개체가 있는지 예측하는 손실
cls_loss : 감지된 객체의 클래스를 예측하는 손실

Instances : 각 에포크마다 감지된 개체 인스턴스의 수, 모델이 객체를 감지하는 능력 파악
Size : 훈련 중 사용된 입력 이미지의 크기

감지매트릭
P : 정밀도, 모든 예측된 양성 감지 사이에서 실제 양성 감지의 비율
R : 재현율, 모든 실제 양성 인스턴스 사이에서 실제 양성 감지의 비율
mAP50 : IoU(Intersection over Union) 임계 값이 0.5인 경우의 평균 정밀도 객체 감지에 일반적으로 사용되는 지표
mAP50-95 : 0.5에서 0.95까지의 IoU임계 값 범위에서의 평균 정밀

(최적화...)
python c:/yolov5/train.py --img 640 --batch 16 --epochs 50 --data c:/data.yaml --weights c:/yolov5/models/yolov5m.pt --device 0 --name exp --optimizer SGD --project c:/yolov5result
python c:/yolov5/train.py --img 640 --batch 16 --epochs 50 --data c:/data.yaml --weights c:/yolov5/models/yolov5m.pt --device 0 --name exp --optimizer Adam --project c:/yolov5result
python c:/yolov5/detect.py --weights C:\yolov5result\exp20\weights\best.pt --img 640 --conf 0.50 --source C:\images --device 0

NVIDIA GeForce RTX 4060 Laptop GPU 16G RAM
11:04 ~ 11:31
python c:/yolov5/train.py --img 640 --batch 16 --epochs 100 --data c:/data.yaml --weights c:/yolov5/models/yolov5m.pt --device 0
python c:/yolov5/detect.py --weights C:\yolov5\runs\train\exp28\weights\best.pt --img 640 --conf 0.50 --source C:\images --device 0

--컵인식률90%이상나옴
python c:/yolov5/train.py --img 640 --batch 16 --epochs 200 --data c:/data.yaml --weights c:/yolov5/models/yolov5m.pt --device 0
![이미지 설명](ujh190806_41.jpg)

