1) 영상출력하기

import cv2

#초당 30프레임 이미지로 구성
#ret : 잘읽어왔는지 True, False
#frame : 1프레임의 이미지 저장

cap = cv2.VideoCapture(0)

while True:
    #동영상에서 이미지를 프레임 단위로 읽어옴
    ret, frame = cap.read()

    if not ret: #파일에 문제가 있거나 동영상이 끝났을 때
        print('이미지 읽기 실패 또는 모두 읽음')
        #비디오 종료
        cap.release()
        #윈도우 실행창 종료
        cv2.destroyAllWindows()
        #반복문 종료
        break

    #동영상을 잘 읽어왔을 때
    cv2.imshow('video', frame)

    #한장의 사진을 0.033초 동안 띄움
    k = cv2.waitKey(33)    

    #1을 누르면 동영상 종료
    if k == 49: #ASCII코드(1)
        print('동영상 종료')
        cap.release()
        cv2.destroyAllWindows()
        break


2) 녹화하기 #1:종료, 2:녹화시작, 3:녹화종료

import cv2

# 녹화하기
try:
    cap = cv2.VideoCapture(0)
    print("동영상 읽기 성공")
except:
    print("동영상 읽기 실패")

# 녹화 설정(녹화하기 위해서는 설정 작업 필요) 
fps = 30.0 # 녹화할 프레임 수
width = int(cap.get(3)) # 녹화 영상의 가로 크기
height = int(cap.get(4)) # 녹화 영상의 세로 크기

# 코덱 설정(동영상을 어떤 형식으로 압출할 것인지)
# MPEG > mp4
# DIVX > avi
fcc = cv2.VideoWriter_fourcc(*'DIVX')

# 녹화 저장 설정
# cv2.VideoWriter(저장할 파일명, 코덱, 프레임 수, 동영상 크기)
out= cv2.VideoWriter('out.avi', fcc, fps, (width,height))

record = False

while True:
    ret, frame = cap.read()
    
    if not ret : 
        print("이미지 읽기 실패 또는 모두 읽음") 
        cap.release()
        cv2.destroyAllWindows()
        break
        
    cv2.imshow('animation',frame)
    out.write(frame)
    
    k = cv2.waitKey(33)
    
    if k == 49:
        print("동영상 종료")
        cap.release()
        cv2.destroyAllWindows()
        break
        
    if k == 50 : # 녹화 시작 버튼(2를 눌렀을 시)
        record = True
        print("녹화 시작")
        
    if record :
        out.write(frame)
        
    if k == 51:
        # 녹화 종료
        out.release()
        print("녹화 종료")

3) 캡쳐하기
import cv2
import os

# Open the video file
cap = cv2.VideoCapture('out.avi')

# Check if the video file was successfully opened
if not cap.isOpened():
    print('Failed to open video file')
    exit()

print('Video file opened successfully')

# Create directory for saving images if it doesn't exist
save_dir = './cap_img/'
os.makedirs(save_dir, exist_ok=True)

num = 0  # Counter for image filenames

while True:
    ret, frame = cap.read()

    if not ret:
        print('Failed to read frame or end of video')
        break

    cv2.imshow('video', frame)

    k = cv2.waitKey(33)

    if k == ord('q'):  # Press 'q' to exit
        print('Exiting...')
        break

    if k == ord('s'):  # Press 's' to save frame as an image
        print('Saving frame as image...')
        image_path = os.path.join(save_dir, 'cap_img{}.jpg'.format(num))
        success = cv2.imwrite(image_path, frame, params=[cv2.IMWRITE_JPEG_PROGRESSIVE, 0])
        if success:
            print('Image saved as', image_path)
            num += 1
        else:
            print('Failed to save image')

# Release VideoCapture and close OpenCV windows
cap.release()
cv2.destroyAllWindows()

4) 픽셀값읽기변경
import cv2

#픽셀값 읽기 : 가로, 세로 값을 입력하면 해당위치의 픽셀값을 출력함
img = cv2.imread('rudy.jpg')

#이미지에서 100, 100의 픽셀값을 출력
img[100,100]

#픽셀값 변경 : 해당 위치에 BGR값을 대입해주면됨
img[100, 300] = [0, 0, 0]
img[101, 300] = [0, 0, 0]
img[100, 301] = [0, 0, 0]
img[101, 301] = [0, 0, 0]

cv2.imshow('dog', img)
cv2.waitKey(0)
cv2.destroyAllWindows()


5) 이미지영역자르기

import cv2

img = cv2.imread('rudy.jpg')

print(img.shape)
print(img.size)

roi_img = img[150:300, 50:200]
cv2.imshow('dog_face', roi_img)

cv2.waitKey(0)
cv2.destroyAllWindows()


6) 이미지에 도형그리기고 텍스트출력하기

import cv2

#이미지에 원그리기 : cv2.circle()
#이미지에 사각형 그리기 : 
#cv2.rectangle(배경이미지,좌상단점좌표,우하단점좌표, 색상, 선두께)
#이미지에 텍스트 입력하기 :
#cv2.putText(배경이미지,출력내용,출력시작좌표,폰트,크기,색상,굵기) 

img = cv2.imread('rudy.jpg')
img = cv2.rectangle(img, (50,150),(200,300),(0,0,255),3)
img = cv2.putText(img, 'Dog', (50,140), cv2.FONT_HERSHEY_SIMPLEX,
                  0.5, (255,0,0), 2)
cv2.imshow('dog', img)

cv2.waitKey(0)
cv2.destroyAllWindows()

7) HSV
원하는 색상만 잘라낼때 이미지안에서 해당 색상을 검출하는데 어떤게 빨간색인지를 찾아야함
RGB는 같은 빨간색이라도 빛이 하나도없으면 검정색으로 보이듯 제대로 색상 파악이 안됨
및에 따라 달라지는 값을 인식하지 못하기 때문에 사용되지 않는다
HSV는 빛에 따른 판단을 할 수 잇기때문에 색상을 추적할 때에는 RGB보다는 HSV를 사용하는게 확실히 추적가능

ㄱ. 색상추적하기
import cv2
import numpy as np

dog = cv2.imread('rudy.jpg')
dog_hsv = cv2.cvtColor(dog, cv2.COLOR_BGR2HSV)

cv2.imshow('dog', dog_hsv)
cv2.waitKey(0)
cv2.destroyAllWindows()

ㄴ. 최소값과 최대값 사이에 있는 값을 마스크로 지정 
범위안에 들어간 값들만 출력
import cv2
import numpy as np

dog = cv2.imread('rudy.jpg')
dog_hsv = cv2.cvtColor(dog, cv2.COLOR_BGR2HSV)

#최소범위
lower = np.array([-10, 100, 100])
#최대범위
upper = np.array([10, 255, 255])

mask = cv2.inRange(dog_hsv, lower, upper)

result = cv2.bitwise_and(dog, dog_hsv, mask = mask)

cv2.imshow('dog', dog_hsv)
cv2.waitKey(0)
cv2.destroyAllWindows()

8) 모서리검출(Canny edge)
cv2.goodFeaturesToTrak(이미지, 모서리개수, 기준값, 코너 점간의 최소거리)
ravel() : 다차원 배열을 1차원 배열로 변환 
좌표값을 사용하여 모서리에 표시하기
cv2.circle(이미지, 좌표, 굵기, 색상, -1) : -1 원 내부에 색 채우는 속성
import cv2
import numpy as np

img = cv2.imread('rudy.jpg')
img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)

#좌표값출력
corners = cv2.goodFeaturesToTrack(img_gray, 25, 0.01, 10)

#정수로변환
corners = np.int0(corners)

#모서리에 표시하기
for i in corners:
    x,y = i.ravel()
    cv2.circle(img, (x,y), 3, (255,0,0), -1)

cv2.imshow('corner', img)

cv2.waitKey(0)
cv2.destroyAllWindows()

9) 윤곽선 검출
cv2.Canny(이미지, 최소값, 최대값)
import cv2

img = cv2.imread('rudy.jpg', cv2.IMREAD_GRAYSCALE)
cv2.imshow('original', img)

#이미지, 최소값, 최대값
edge = cv2.Canny(img, 50, 250)
edge_reverse = cv2.bitwise_not(edge)

cv2.imshow('edge', edge)
cv2.imshow('edge_reverse', edge_reverse)

cv2.waitKey(0)
cv2.destroyAllWindows()

10) 얼굴, 눈 영역 검출
face_cascade.detectMultiScale(이미지, 스케일값, 최소이웃값)
출력돤 값들은 x좌표, y좌표, 길이, 높이가 한묶음으로 출력된다
import cv2

#얼굴영역검출
face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')

#이미지를 읽어옴
img = cv2.imread('faces.jpeg')

if img is None:
    print("이미지를 읽을 수 없습니다.")
    exit()

#이미지를 흑백으로 변환
img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

#이미지명, 스케일값, 최소이웃값
faces = face_cascade.detectMultiScale(img_gray, 1.3, 5)

for (x,y,w,h) in faces:
    cv2.rectangle(img, (x,y), (x+w, y+h), (255,0,0), 2)

cv2.imshow('face', img)

cv2.waitKey(0)
cv2.destroyAllWindows()

11) 눈검출
import cv2

#얼굴 영역 검출
face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')

#눈 영역 검출
eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')

img = cv2.imread('faces.jpeg')
img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

#이미지명, 스케일값, 최소이웃값
faces = face_cascade.detectMultiScale(img_gray, 1.3, 5)

for (x,y,w,h) in faces:
    cv2.rectangle(img, (x,y), (x+w, y+h), (255,0,0),2)
    #얼굴영역 안에서 눈검출
    roi_gray = img_gray[y:y+h, x:x+w]
    roi_color = img[y:y+h, x:x+w]
    #눈영역검출
    eyes = eye_cascade.detectMultiScale(roi_gray, 1.1,2)
    for(ex, ey, ew, eh) in eyes:
        cv2.rectangle(roi_color, (ex,ey),(ex+ew, ey+eh),(0,0,255),2)

cv2.imshow('face & eye', img)
cv2.waitKey(0)
cv2.destroyAllWindows()

11) 동영상 영역 검출
import cv2

#얼굴 영역 검출
face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')

#눈 영역 검출
eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')

try:
    cap = cv2.VideoCapture(0)
    print('읽기성공')
except:
    print('읽기 실패')

while True:
    ret, frame = cap.read()

    if not ret:
        print('실패 또는 모두 읽음')
        cap.release()
        cv2.destroyAllWindows()
        break

    img_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    #이미지명, 스케일값, 최소이웃값
    faces = face_cascade.detectMultiScale(img_gray, 1.3, 5)

    for (x,y,w,h) in faces:
        cv2.rectangle(frame, (x,y), (x+w, y+h), (255,0,0), 2)

        #얼굴영역 안에서 눈 검출
        roi_gray = img_gray[y:y+h, x:x+w]
        roi_color = frame[y:y+h, x:x+w]

        #눈영역 검출
        eyes = eye_cascade.detectMultiScale(roi_gray, 1.1, 2)
        for(ex,ey,ew,eh) in eyes:
            cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0,0,255),2)

    cv2.imshow('video', frame)

    k = cv2.waitKey(10)

    if k == 49:
        print('종료')
        cap.release()
        cv2.destroyAllWindows()
        break

11) 이미지에서 원찾기
